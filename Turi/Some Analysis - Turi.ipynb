{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2: Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "# import ML packages\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import neural_network\n",
    "# import Plotting pckgs\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingSet = pd.read_csv('../CSVs/finalTraining.csv')\n",
    "testingSet = pd.read_csv('../CSVs/finalTesting.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingSet = trainingSet.loc[trainingSet.duration < 100000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aca hize un df del tipo test para comparar el resultado pero creo que es preferible dividir el set original de training en, train y test, al final de todo usamos este y listo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's study correlation between data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingSet.corr()['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                  \n",
    "X1 = trainingSet [['id','historical', 'subscription_type_Subscriber','subscription_type_Customer', 'distance','start_minute', 'start_station_id', 'end_station_id',  'wind_dir_degrees', 'max_gust_speed_kmh','precipitation_cm', 'mean_humidity', 'business_day','weekday','month','year']]\n",
    "X2 = testingSet [['id','historical', 'subscription_type_Subscriber','subscription_type_Customer', 'distance','start_minute', 'start_station_id', 'end_station_id',  'wind_dir_degrees', 'max_gust_speed_kmh','precipitation_cm', 'mean_humidity', 'business_day','weekday','month','year']]\n",
    " \n",
    "\n",
    "y = trainingSet.duration\n",
    "\n",
    "X_train = X1\n",
    "X_test = X2\n",
    "y_train = y\n",
    "y_test = ## KAGGLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainingSet = trainingSet.loc[trainingSet.duration < 100000,:]\n",
    "\n",
    "# dfTrip = pd.read_csv('../CSVs/trip.csv')\n",
    "# dfTrip = dfTrip.loc[:,['id','duration']]\n",
    "# dfTrip = dfTrip.rename(columns={'duration':'durationPosta'})\n",
    "# dfScore = pd.merge(testingSet,dfTrip,on =['id'],how = 'inner')\n",
    "\n",
    "# X1 = trainingSet [['id','historical', 'subscription_type_Subscriber','subscription_type_Customer', 'distance','start_minute', 'start_station_id', 'end_station_id',  'wind_dir_degrees', 'max_gust_speed_kmh','precipitation_cm', 'mean_humidity', 'business_day','weekday','month','year']]\n",
    "# X2 = testingSet [['id','historical', 'subscription_type_Subscriber','subscription_type_Customer', 'distance','start_minute', 'start_station_id', 'end_station_id',  'wind_dir_degrees', 'max_gust_speed_kmh','precipitation_cm', 'mean_humidity', 'business_day','weekday','month','year']]\n",
    "# y = trainingSet.duration\n",
    "\n",
    "# X_train = X1\n",
    "# X_test = X2\n",
    "# y_train = y\n",
    "# y_test = dfScore.durationPosta\n",
    "\n",
    "# print ('Scaling data ...')\n",
    "\n",
    "# # min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# # X_train= min_max_scaler.fit_transform(X_train)\n",
    "# # X_test= min_max_scaler.fit_transform(X_test)\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "# scaler = StandardScaler()\n",
    "# # Fit only to the training data\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "# print (\"---- Start algorithm ---- \")\n",
    "# RF = RandomForestRegressor(n_estimators=50, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_split=1e-07, bootstrap=True, oob_score=True, n_jobs=1, random_state=3, verbose=1, warm_start=False)\n",
    "\n",
    "# print (\"Fitting ...\")\n",
    "\n",
    "# RF.fit(X_train,y_train)\n",
    "\n",
    "# print (\"Features sorted by their score:\")\n",
    "\n",
    "# prediction = RF.predict(X_test)\n",
    "# print (\"Prediction:\" ,prediction)\n",
    "# print (\"Error cuadratico medio: %.2f \" % np.mean((prediction - y_test)**2))\n",
    "\n",
    "\n",
    "# dfComparison = pd.DataFrame(prediction)\n",
    "# dfScore = dfScore.loc[:,['id']]\n",
    "# dfScore['duracion'] = dfComparison\n",
    "# # Y ACA HACER EL PASO A .CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train= min_max_scaler.fit_transform(X_train)\n",
    "X_test= min_max_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('Scaling data ...')\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train= min_max_scaler.fit_transform(X_train)\n",
    "X_test= min_max_scaler.fit_transform(X_test)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print (\"---- Start algorithm ---- \")\n",
    "RF = RandomForestRegressor(n_estimators=30, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_split=1e-07, bootstrap=True, oob_score=True, n_jobs=1, random_state=3, verbose=1, warm_start=False)\n",
    "\n",
    "print (\"Fitting ...\")\n",
    "\n",
    "RF.fit(X_train,y_train)\n",
    "\n",
    "print (\"Features sorted by their score:\")\n",
    "\n",
    "prediction = RF.predict(X_test)\n",
    "print (\"Prediction:\" ,prediction)\n",
    "print (\"Error cuadratico medio: %.2f \" % np.mean((prediction - y_test)**2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('Scaling data ...')\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train= min_max_scaler.fit_transform(X_train)\n",
    "X_test= min_max_scaler.fit_transform(X_test)\n",
    "# Create linear regression object\n",
    "print (\"---- Start algorithm ---- \")\n",
    "regr = linear_model.LinearRegression()\n",
    "print (\"Fitting ...\")\n",
    "regr.fit(X_train, y_train)\n",
    "print (\"Features sorted by their score:\")\n",
    "\n",
    "prediction = regr.predict(X_test)\n",
    "print (\"Prediction:\" ,prediction)\n",
    "print (\"Error cuadratico medio: %.2f \" % np.mean((prediction - y_test)**2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train= min_max_scaler.fit_transform(X_train)\n",
    "X_test= min_max_scaler.fit_transform(X_test)\n",
    "print (\"---- Start algorithm ---- \")\n",
    "gbr = GradientBoostingRegressor(learning_rate = 0.12,\n",
    "                                n_estimators = 30,\n",
    "                                max_depth = 8,\n",
    "                                min_samples_leaf = 1,\n",
    "                                random_state = 3)\n",
    "\n",
    "print (\"Fitting ...\")\n",
    "gbr.fit(X_train, y_train)\n",
    "print \"Features sorted by their score:\"\n",
    "prediction = gbr.predict(X_test)\n",
    "\n",
    "print (\"Prediction:\" ,prediction)\n",
    "print (\"Error cuadratico medio: %.2f \" % np.mean((prediction - y_test)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Puedo variar el hidden_layer a mas grande o el random_state a mas grande\n",
    "print (\"---- Start algorithm ---- \")\n",
    "MLP = MLPRegressor(\n",
    "    hidden_layer_sizes=(100,100,100,100),  activation='relu', solver='sgd', alpha=0.1, batch_size=2000,\n",
    "    learning_rate='adaptive', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True,\n",
    "    random_state=0, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "    early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "print (\"Fitting ...\")\n",
    "MLP.fit(X_train,y_train)\n",
    "prediction = MLP.predict(X_test)\n",
    "print (prediction)\n",
    "print (\"Error cuadratico medio: %.2f \" % np.mean((prediction - y_test)**2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# import ML packages\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import neural_network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "in_out_neurons = 1\n",
    "hidden_neurons = 50\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# n_prev = 100, 2 values per x axis\n",
    "model.add(Dense(19, input_dim=19, activation=\"relu\"))\n",
    "model.add(Dense(6, activation=\"relu\"))\n",
    "# model.add(18, Activation('relu'))          no se que onda esto\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# For a mean squared error regression problem\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "    optimizer=\"rmsprop\",\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# For a mean squared error regression problem\n",
    "model.compile(optimizer='adam',metrics=['accuracy'],loss='mse')\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=700, nb_epoch=5, validation_data=(X_test, y_test), verbose=1)\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "predicted = model.predict(X_test, batch_size=700)\n",
    "\n",
    "\n",
    "\n",
    "print('Plotting Results')\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(y_test)\n",
    "plt.title('Expected')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(predicted)\n",
    "plt.title('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejores features para el set de datos, se implementa luego del .fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = sorted(zip(map(lambda x: round(x, 4), RF.feature_importances_), X1), \n",
    "             reverse=True)\n",
    "print (list (n_features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
