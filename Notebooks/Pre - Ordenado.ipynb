{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TP2: Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import scipy.spatial\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"*****Data loading*****\"\n",
    "print \"loading station csv\"\n",
    "stationDF = pd.read_csv('../CSVs/station.csv')\n",
    "print \"loading trip train csv\"\n",
    "trainingSet = pd.read_csv('../CSVs/trip_train.csv')\n",
    "print \"loading trip test csv\"\n",
    "testingSet = pd.read_csv('../CSVs/trip_test.csv')\n",
    "\n",
    "# GLORIOSO DF DEL TP1\n",
    "# (0 = Monday, 1 = Tuesday...)\n",
    "print \"loading dfSF_Bay csv\"\n",
    "dfSF_Bay = pd.read_csv('../CSVs/dfSF_Bay.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Basic data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"stationDF.shape: \", stationDF.shape\n",
    "print \"trainingSet.shape: \", trainingSet.shape\n",
    "print \"testingSet.shape: \", testingSet.shape\n",
    "print \"dfSF_Bay.shape: \", dfSF_Bay.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Distancias entre estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"*****Working on station distances*****\"\n",
    "# Create new temporary dataframe with distances\n",
    "distancesDF = pd.DataFrame(columns=[\"start_station_id\", \"end_station_id\", \"distance\"])\n",
    "\n",
    "# Calculate distances between stations\n",
    "for station, lat, lon in zip(stationDF.id, stationDF.lat, stationDF.long):\n",
    "    for station2, lat2, lon2 in zip(stationDF.id, stationDF.lat, stationDF.long):\n",
    "        distancesDF = distancesDF.append({\n",
    "            \"start_station_id\": station,\n",
    "            \"end_station_id\": station2,\n",
    "            \"distance\": scipy.spatial.distance.cityblock([lat, lon], [lat2, lon2])\n",
    "        }, ignore_index=True)\n",
    "\n",
    "distancesDF['start_station_id'] = distancesDF.start_station_id.astype(int)\n",
    "distancesDF['end_station_id'] = distancesDF.end_station_id.astype(int)\n",
    "\n",
    "# Merge this new data to training and testing sets\n",
    "trainingSet = pd.merge(trainingSet,distancesDF,on =['start_station_id','end_station_id'],how = 'inner')\n",
    "testingSet = pd.merge(testingSet,distancesDF,on =['start_station_id','end_station_id'],how = 'inner')\n",
    "\n",
    "# delete auxiliary distances df\n",
    "del distancesDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Process date & time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"*****Converting necessary data to dateTime*****\"\n",
    "# Convert necessary data to dateTime\n",
    "dfSF_Bay['date'] = pd.to_datetime(dfSF_Bay.date)\n",
    "\n",
    "trainingSet['start_date'] = pd.to_datetime(trainingSet.start_date)\n",
    "trainingSet['end_date'] = pd.to_datetime(trainingSet.end_date)\n",
    "\n",
    "testingSet['start_date'] = pd.to_datetime(testingSet.start_date)\n",
    "testingSet['end_date'] = pd.to_datetime(testingSet.end_date)\n",
    "\n",
    "# Create new features related to date & time based on the unique 'date' feature\n",
    "# Work with training set\n",
    "trainingSet['start_dayOfWeek'] = trainingSet.start_date.dt.dayofweek\n",
    "trainingSet['start_week'] = trainingSet.start_date.dt.week\n",
    "trainingSet['start_quarter'] = trainingSet.start_date.dt.quarter\n",
    "trainingSet['start_time'] = trainingSet.start_date.dt.time\n",
    "trainingSet['start_hour'] = trainingSet.start_date.dt.hour\n",
    "trainingSet['start_minute'] = trainingSet.start_date.dt.minute\n",
    "trainingSet['start_year'] = trainingSet.start_date.dt.year\n",
    "trainingSet['start_month'] = trainingSet.start_date.dt.month\n",
    "trainingSet['start_day'] = trainingSet.start_date.dt.day\n",
    "trainingSet['start_date'] = trainingSet.start_date.dt.date\n",
    "\n",
    "trainingSet['end_dayOfWeek'] = trainingSet.end_date.dt.dayofweek\n",
    "trainingSet['end_week'] = trainingSet.end_date.dt.week\n",
    "trainingSet['end_quarter'] = trainingSet.end_date.dt.quarter\n",
    "trainingSet['end_time'] = trainingSet.end_date.dt.time\n",
    "trainingSet['end_hour'] = trainingSet.end_date.dt.hour\n",
    "trainingSet['end_minute'] = trainingSet.end_date.dt.minute\n",
    "trainingSet['end_year'] = trainingSet.end_date.dt.year\n",
    "trainingSet['end_month'] = trainingSet.end_date.dt.month\n",
    "trainingSet['end_day'] = trainingSet.end_date.dt.day\n",
    "trainingSet['end_date'] = trainingSet.end_date.dt.date\n",
    "\n",
    "trainingSet['year'] = pd.to_datetime(trainingSet['start_date']).dt.year\n",
    "trainingSet['month'] = pd.to_datetime(trainingSet['start_date']).dt.month\n",
    "trainingSet['weekday'] = pd.to_datetime(trainingSet['start_date']).dt.weekday\n",
    "\n",
    "# Work with testing set\n",
    "testingSet['start_dayOfWeek'] = testingSet.start_date.dt.dayofweek\n",
    "testingSet['start_week'] = testingSet.start_date.dt.week\n",
    "testingSet['start_quarter'] = testingSet.start_date.dt.quarter\n",
    "testingSet['start_time'] = testingSet.start_date.dt.time\n",
    "testingSet['start_hour'] = testingSet.start_date.dt.hour\n",
    "testingSet['start_minute'] = testingSet.start_date.dt.minute\n",
    "testingSet['start_year'] = testingSet.start_date.dt.year\n",
    "testingSet['start_month'] = testingSet.start_date.dt.month\n",
    "testingSet['start_day'] = testingSet.start_date.dt.day\n",
    "testingSet['start_date'] = testingSet.start_date.dt.date\n",
    "\n",
    "testingSet['end_dayOfWeek'] = testingSet.end_date.dt.dayofweek\n",
    "testingSet['end_week'] = testingSet.end_date.dt.week\n",
    "testingSet['end_quarter'] =testingSet.end_date.dt.quarter\n",
    "testingSet['end_time'] = testingSet.end_date.dt.time\n",
    "testingSet['end_hour'] = testingSet.end_date.dt.hour\n",
    "testingSet['end_minute'] = testingSet.end_date.dt.minute\n",
    "testingSet['end_year'] = testingSet.end_date.dt.year\n",
    "testingSet['end_month'] = testingSet.end_date.dt.month\n",
    "testingSet['end_day'] = testingSet.end_date.dt.day\n",
    "testingSet['end_date'] = testingSet.end_date.dt.date\n",
    "\n",
    "testingSet['year'] = pd.to_datetime(testingSet['start_date']).dt.year\n",
    "testingSet['month'] = pd.to_datetime(testingSet['start_date']).dt.month\n",
    "testingSet['weekday'] = pd.to_datetime(testingSet['start_date']).dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"trainingSet cols values\", list(trainingSet.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"testingSet cols values\", list(testingSet.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feature Historico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"*****Working on historic feature*****\"\n",
    "print \"***Calculating historic feature***\"\n",
    "import math\n",
    "listaStart = []\n",
    "listaEnd = []\n",
    "for i in list(trainingSet.start_station_id.values):\n",
    "    if i not in listaStart:\n",
    "        listaStart.append(i)\n",
    "for i in list(trainingSet.end_station_id.values):\n",
    "    if i not in listaEnd:\n",
    "        listaEnd.append(i)\n",
    "listaHistorico = []\n",
    "for i in listaStart:\n",
    "    for j in listaEnd:\n",
    "        df = trainingSet[(trainingSet['start_station_id'] == i) & (trainingSet['end_station_id'] == j)]\n",
    "        historico = df.duration.mean()\n",
    "        if (not(math.isnan(historico))):\n",
    "            listaHistorico.append([i,j,historico])\n",
    "        \n",
    "listaHistorico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "starStationId = []\n",
    "endStationId = []\n",
    "historical = []\n",
    "for x in listaHistorico:\n",
    "    starStationId.append(x[0])\n",
    "    endStationId.append(x[1])\n",
    "    historical.append(x[2])\n",
    "\n",
    "data = {\n",
    "    'start_station_id' : starStationId,\n",
    "    'end_station_id' : endStationId,\n",
    "    'historical' : historical,\n",
    "}\n",
    "\n",
    "dfData = pd.DataFrame(data,columns = ['start_station_id','end_station_id','historical'])\n",
    "dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"**Merging historic feature**\"\n",
    "# Merge this new data to training and testing dfs\n",
    "# Training\n",
    "trainingSet = pd.merge(trainingSet,dfData,on=['start_station_id', 'end_station_id'],how = 'inner') \n",
    "\n",
    "trainingSet['historical'] = trainingSet.historical.astype(int)\n",
    "\n",
    "# Testing\n",
    "testingSet = pd.merge(testingSet, dfData, on=['start_station_id', 'end_station_id'], how='inner')\n",
    "\n",
    "testingSet['historical'] = testingSet.historical.astype(int)\n",
    "\n",
    "# delete auxiliar dataframe\n",
    "del dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"trainingSet.shape: \", trainingSet.shape\n",
    "print \"testingSet.shape: \", testingSet.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The difference in the shapes is due to the duration feature used in the training set, which was used to calculate the historical feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Trabajamos con dfSF_Bay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert necessary data to dateTime\n",
    "dfSF_Bay['date'] = pd.to_datetime(dfSF_Bay.date)\n",
    "\n",
    "trainingSet['start_date'] = pd.to_datetime(trainingSet.start_date)\n",
    "trainingSet['end_date'] = pd.to_datetime(trainingSet.end_date)\n",
    "\n",
    "testingSet['start_date'] = pd.to_datetime(testingSet.start_date)\n",
    "testingSet['end_date'] = pd.to_datetime(testingSet.end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"***Merging dfSF_Bay data***\"\n",
    "# Merge trainingSet with new data\n",
    "\n",
    "testingSet = pd.merge(testingSet,dfSF_Bay,left_on ='start_date',right_on='date',how = 'inner')\n",
    "trainingSet = pd.merge(trainingSet,dfSF_Bay,left_on ='start_date',right_on='date',how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "testingSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trainingSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Discretizacion y Normalizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Discretizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(trainingSet.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(testingSet.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"*****Discretizacion y Normalizacion*****\"\n",
    "print \"*****Discretizacion*****\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def crearLista (listadoCompleto):\n",
    "    listaReducida = []\n",
    "    for i in listadoCompleto:\n",
    "        if i not in listaReducida:\n",
    "            listaReducida.append(i)\n",
    "    listaReducida.sort()\n",
    "    return listaReducida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def discretizar(columna,nombre, df):\n",
    "    listaReducida = crearLista(columna)\n",
    "    v = list(range(len(columna)))\n",
    "    listaCompleta = list(columna)\n",
    "    for i in listaReducida:\n",
    "        for j in range(len(listaCompleta)):\n",
    "            if(listaCompleta[j] == i):\n",
    "                v[j] = 1\n",
    "            else:\n",
    "                v[j] = 0\n",
    "        df[nombre+str(i)] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"Discretizando start_station_name...\"\n",
    "discretizar(trainingSet.start_station_name,'start ', trainingSet)\n",
    "discretizar(testingSet.start_station_name,'start ', testingSet)\n",
    "\n",
    "print \"Discretizando end_station_name...\"\n",
    "discretizar(trainingSet.end_station_name,'end ', trainingSet)\n",
    "discretizar(testingSet.end_station_name,'end ', testingSet)\n",
    "\n",
    "print \"Discretizando start_dayOfWeek...\"\n",
    "discretizar(trainingSet.start_dayOfWeek,'start_dayOfWeek_id', trainingSet)\n",
    "discretizar(testingSet.start_dayOfWeek,'start_dayOfWeek_id', testingSet)\n",
    "\n",
    "print \"Discretizando end_dayOfWeek...\"\n",
    "discretizar(trainingSet.end_dayOfWeek,'end_dayOfWeek_id', trainingSet)\n",
    "discretizar(testingSet.end_dayOfWeek,'end_dayOfWeek_id', testingSet)\n",
    "\n",
    "print \"Discretizando subscription_type_...\"\n",
    "discretizar(trainingSet.subscription_type,'subscription_type_', trainingSet)\n",
    "discretizar(testingSet.subscription_type,'subscription_type_', testingSet)\n",
    "\n",
    "print \"Discretizando start_year...\"\n",
    "discretizar(trainingSet.start_year,'start_year_', trainingSet)\n",
    "discretizar(testingSet.start_year,'start_year_', testingSet)\n",
    "\n",
    "print \"Discretizando end_year_...\"\n",
    "discretizar(trainingSet.end_year,'end_year_', trainingSet)\n",
    "discretizar(testingSet.end_year,'end_year_', testingSet)\n",
    "\n",
    "print \"Discretizando start_month...\"\n",
    "discretizar(trainingSet.start_month,'start_month_', trainingSet)\n",
    "discretizar(testingSet.start_month,'start_month_', testingSet)\n",
    "\n",
    "print \"Discretizando end_month...\"\n",
    "discretizar(trainingSet.end_month,'end_month_', trainingSet)\n",
    "discretizar(testingSet.end_month,'end_month_', testingSet)\n",
    "\n",
    "print \"Discretizando start_day...\"\n",
    "discretizar(trainingSet.start_day,'start_day_', trainingSet)\n",
    "discretizar(testingSet.start_day,'start_day_', testingSet)\n",
    "\n",
    "print \"Discretizando end_day...\"\n",
    "discretizar(trainingSet.end_day,'end_day_', trainingSet)\n",
    "discretizar(testingSet.end_day,'end_day_', testingSet)\n",
    "\n",
    "print \"Discretizando start_quarter...\"\n",
    "discretizar(trainingSet.start_quarter,'start_quarter_', trainingSet)\n",
    "discretizar(testingSet.start_quarter,'start_quarter_', testingSet)\n",
    "\n",
    "print \"Discretizando end_quarter...\"\n",
    "discretizar(trainingSet.end_quarter,'end_quarter_', trainingSet)\n",
    "discretizar(testingSet.end_quarter,'end_quarter_', testingSet)\n",
    "\n",
    "print \"Discretizando start_hour...\"\n",
    "discretizar(trainingSet.start_hour,'start_hour_', trainingSet)\n",
    "discretizar(testingSet.start_hour,'start_hour_', testingSet)\n",
    "\n",
    "print \"Discretizando end_hour...\"\n",
    "discretizar(trainingSet.end_hour,'end_hour', trainingSet)\n",
    "discretizar(testingSet.end_hour,'end_hour', testingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"Dropping trash columns...\"\n",
    "trainingSet = trainingSet.drop(labels = ['start_date', \n",
    "                                         'end_station_name',\n",
    "                                         'start_station_name',\n",
    "                                         'end_date',\n",
    "                                         'subscription_type',\n",
    "                                         'zip_code',\n",
    "                                         'start_time',\n",
    "                                         'end_time',\n",
    "                                         'start_dayOfWeek',\n",
    "                                         'end_dayOfWeek',\n",
    "                                         'start_year',\n",
    "                                         'end_year',\n",
    "                                         'start_month',\n",
    "                                         'end_month',\n",
    "                                         'start_day',\n",
    "                                         'end_day',\n",
    "                                         'start_quarter',\n",
    "                                         'end_quarter',\n",
    "                                         'start_hour',\n",
    "                                         'end_hour'\n",
    "                                        ],axis = 1)\n",
    "\n",
    "testingSet = testingSet.drop(labels = ['start_date', \n",
    "                                         'end_station_name',\n",
    "                                         'start_station_name',\n",
    "                                         'end_date',\n",
    "                                         'subscription_type',\n",
    "                                         'zip_code',\n",
    "                                         'start_time',\n",
    "                                         'end_time',\n",
    "                                         'start_dayOfWeek',\n",
    "                                         'end_dayOfWeek',\n",
    "                                         'start_year',\n",
    "                                         'end_year',\n",
    "                                         'start_month',\n",
    "                                         'end_month',\n",
    "                                         'start_day',\n",
    "                                         'end_day',\n",
    "                                         'start_quarter',\n",
    "                                         'end_quarter',\n",
    "                                         'start_hour',\n",
    "                                         'end_hour'\n",
    "                                        ],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"trainingSet.shape: \", trainingSet.shape\n",
    "print \"testingSet.shape: \", testingSet.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Normalizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"*****Normalizacion*****\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"Saving temp csvs...\"\n",
    "trainingSet.to_csv('../CSVs/tempTraining.csv')\n",
    "testingSet.to_csv('../CSVs/tempTesting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# trainingSet = pd.read_csv('../CSVs/tempTraining.csv')\n",
    "# testingSet = pd.read_csv('../CSVs/tempTesting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"Normalizando data...\"\n",
    "durationNormalize = preprocessing.normalize(trainingSet.duration)\n",
    "trainingSet['duration'] = durationNormalize[0]\n",
    "maxTemperatureNormalize = preprocessing.normalize(trainingSet.max_temperature_c)\n",
    "trainingSet['max_temperature_c'] = maxTemperatureNormalize[0]\n",
    "minTemperatureNormalize= preprocessing.normalize(trainingSet.min_temperature_c)\n",
    "trainingSet['min_temperature_c'] = minTemperatureNormalize[0]\n",
    "maxHumidityNormalize = preprocessing.normalize(trainingSet.max_humidity)\n",
    "trainingSet['max_humidity'] = maxHumidityNormalize[0]\n",
    "maxSeaLevelPressureNormalize = preprocessing.normalize(trainingSet.max_sea_level_pressure_cm)\n",
    "trainingSet['max_sea_level_pressure_cm'] = maxSeaLevelPressureNormalize[0]\n",
    "precipitationNormalize = preprocessing.normalize(trainingSet.precipitation_cm)\n",
    "trainingSet['precipitation_cm'] = precipitationNormalize[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"filtrando por duracion...\"\n",
    "trainingSet = trainingSet.loc[trainingSet.duration < 1000000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trainingSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"Saving temp csvs...\"\n",
    "trainingSet.to_csv('../CSVs/tempTraining.csv')\n",
    "testingSet.to_csv('../CSVs/tempTesting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"Saving to new csvs...\"\n",
    "print \"Saving trainingSet to ../CSVs/finalTraining.csv...\"\n",
    "trainingSet.to_csv('../CSVs/finalTraining.csv')\n",
    "print \"Saving testingSet to ../CSVs/finalTesting.csv...\"\n",
    "testingSet.to_csv('../CSVs/finalTesting.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
