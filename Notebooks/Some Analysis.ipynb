{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2: Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# import ML packages\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import neural_network\n",
    "# import Plotting pckgs\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingSet = pd.read_csv('../CSVs/finalTraining.csv')\n",
    "testingSet = pd.read_csv('../CSVs/finalTesting.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aca hize un df del tipo test para comparar el resultado pero creo que es preferible dividir el set original de training en, train y test, al final de todo usamos este y listo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrip = pd.read_csv('../CSVs/trip.csv')\n",
    "dfTrip = dfTrip.loc[:,['id','duration']]\n",
    "dfTrip = dfTrip.rename(columns={'duration':'durationPosta'})\n",
    "dfScore = pd.merge(testingSet,dfTrip,on =['id'],how = 'inner')\n",
    "dfScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingSet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testingSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingSet.duration.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's study correlation between data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet.corr()['duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the duration is most correlated with:\n",
    "    - start_dayOfWeek     0.018351\n",
    "    - end_dayOfWeek       0.013753\n",
    "    - end_hour            0.009626\n",
    "    - start_station_id   -0.007001\n",
    "    - weekday                      0.018351\n",
    "    - distance                     0.004053\n",
    "    - min_temperature_c            0.002477\n",
    "    - max_humidity                 0.001039\n",
    "    - historical                   0.120417\n",
    "    - distance                     0.004053\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X1 = trainingSet [['historical', 'subscription_type_Subscriber','subscription_type_Customer', 'distance', 'id', 'bike_id', 'start_minute', 'start_station_id', 'end_station_id', 'viajes', 'wind_dir_degrees', 'max_gust_speed_kmh','min_sea_level_pressure_cm', 'min_humidity', 'max_sea_level_pressure_cm']]\n",
    "X2 = testingSet [['historical', 'subscription_type_Subscriber','subscription_type_Customer', 'distance', 'id', 'bike_id', 'start_minute', 'start_station_id', 'end_station_id', 'viajes', 'wind_dir_degrees', 'max_gust_speed_kmh','min_sea_level_pressure_cm', 'min_humidity', 'max_sea_level_pressure_cm']]\n",
    "  \n",
    "y = trainingSet.duration\n",
    "\n",
    "X_train = X1\n",
    "X_test = X2\n",
    "y_train = y\n",
    "y_test = dfScore.durationPosta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (y_test.shape)\n",
    "print (prediction.shape)\n",
    "print (X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Scaling data ...')\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print (\"---- Start algorithm ---- \")\n",
    "RF = RandomForestRegressor(n_estimators=100, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_split=1e-07, bootstrap=True, oob_score=True, n_jobs=1, random_state=3, verbose=1, warm_start=False)\n",
    "\n",
    "print (\"Fitting ...\")\n",
    "\n",
    "RF.fit(X_train,y_train)\n",
    "\n",
    "print \"Features sorted by their score:\"\n",
    "\n",
    "prediction = RF.predict(X_test)\n",
    "print (\"Prediction:\" ,prediction)\n",
    "print (\"Error cuadratico medio: %.2f \" % np.mean((prediction - y_test)**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Scaling data ...')\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Create linear regression object\n",
    "print (\"---- Start algorithm ---- \")\n",
    "regr = linear_model.LinearRegression()\n",
    "print (\"Fitting ...\")\n",
    "regr.fit(X_train, y_train)\n",
    "print \"Features sorted by their score:\"\n",
    "\n",
    "prediction = regr.predict(X_test)\n",
    "print (\"Prediction:\" ,prediction)\n",
    "print (\"Error cuadratico medio: %.2f \" % np.mean((prediction - y_test)**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('Scaling data ...')\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print (\"---- Start algorithm ---- \")\n",
    "gbr = GradientBoostingRegressor(learning_rate = 0.12,\n",
    "                                n_estimators = 10,\n",
    "                                max_depth = 8,\n",
    "                                min_samples_leaf = 1,\n",
    "                                random_state = 2)\n",
    "\n",
    "print (\"Fitting ...\")\n",
    "regr.fit(X_train, y_train)\n",
    "print \"Features sorted by their score:\"\n",
    "\n",
    "prediction = regr.predict(X_test)\n",
    "print (\"Prediction:\" ,prediction)\n",
    "print (\"Error cuadratico medio: %.2f \" % np.mean((prediction - y_test)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = sorted(zip(map(lambda x: round(x, 4), RF.feature_importances_), X1), \n",
    "             reverse=True)\n",
    "print (list (n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot (y_test,  color='black')\n",
    "plt.plot(prediction, color='blue')\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF.fit_transform(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Puedo variar el hidden_layer a mas grande o el random_state a mas grande\n",
    "MLP = MLPRegressor(\n",
    "    hidden_layer_sizes=(100,),  activation='relu', solver='adam', alpha=0.001, batch_size='auto',\n",
    "    learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
    "    random_state=0, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "    early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK\n",
    "## LINEAR_1 : Error cuadratico medio: 1849699707.76 \n",
    "                                                    \n",
    "## RANDOM FOREST:  Error cuadratico medio: 157041082.02\n",
    "\n",
    "## GRADIENT BOOST: Error cuadratico medio: 52043963.30 \n",
    "                                                                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
